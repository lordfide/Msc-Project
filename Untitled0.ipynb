{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lordfide/Msc-Project/blob/Code/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDeFzfAyNI8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WbHreotaVywZ",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  (X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "  X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "  return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I2GVFUxg3VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(noise_shape=(100,)):\n",
        "    Input = tf.keras.Input(noise_shape)\n",
        "    x = tf.keras.layers.Dense(128 * 7 * 7, activation=\"relu\")(Input)\n",
        "    x = tf.keras.layers.Reshape((7, 7, 128))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tf.keras.layers.UpSampling2D()(x)\n",
        "    x = tf.keras.layers.Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tf.keras.layers.UpSampling2D()(x)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tf.keras.layers.Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
        "    out = tf.keras.layers.Activation(\"tanh\")(x)\n",
        "    model = tf.keras.layers.Model(Input, out)\n",
        "    print(\"-- Generator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDD6wEcjhGZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "    Input = tf.keras.Input(img_shape)\n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(Input)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = tf.keras.layers.Dropout(0.25)(x)\n",
        "    x = tf.keras.layers.Transpose(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = TransposeZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
        "    x = (LeakyReLU(alpha=0.2))(x)\n",
        "    x = tf.keras.layers.Dropout(0.25)(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = tf.keras.layers.Dropout(0.25)(x)\n",
        "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
        "    x = tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = tf.keras.layers.Dropout(0.25)(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.layers.Model(Input, out)\n",
        "    print(\"-- Discriminator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88QWK5v_ETq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "generator = build_generator()\n",
        "z = tf.keras.Input(shape=(100,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "real = discriminator(img)\n",
        "combined = Model(z, real)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXxU0kL8HvTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "optimizer=disc_optimizer,\n",
        "metrics=['accuracy'])\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "combined.compile(loss='binary_crossentropy', optimizer=gen_optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3sDiPEMDr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = X_train.shape[0]\n",
        "num_batches = int(num_examples / float(batch_size))\n",
        "half_batch = int(batch_size / 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYdPFe4MTsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs + 1):\n",
        "for batch in range(num_batches):\n",
        "# noise images for the batch\n",
        "noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "fake_images = generator.predict(noise)\n",
        "fake_labels = np.zeros((half_batch, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV16DznRMcDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# real images for batch\n",
        "idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "real_images = X_train[idx]\n",
        "real_labels = np.ones((half_batch, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x05lYnfrMqeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the discriminator (real classified as ones and \n",
        "generated as zeros)\n",
        "d_loss_real = discriminator.train_on_batch(real_images, \n",
        "real_labels)\n",
        "d_loss_fake = discriminator.train_on_batch(fake_images, \n",
        "fake_labels)\n",
        "d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "noise = np.random.normal(0, 1, (batch_size, 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVsxenZtNey9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_imgs(generator, epoch, batch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "      for j in range(c): \n",
        "        axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "        cnt += 1\n",
        "        fig.savefig(\"images/mnist_%d_%d.png\" % (epoch, batch))\n",
        "        plt.close()\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI5Q28sPM1mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the generator\n",
        "g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "# Plot the progress\n",
        "print(\"Epoch %d Batch %d/%d [D loss: %f, acc.: %.2f%%] [G loss: \n",
        "%f]\" %\n",
        "(epoch,batch, num_batches, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "if batch % 50 == 0:\n",
        "save_imgs(generator, epoch, batch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}